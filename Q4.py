# -*- coding: utf-8 -*-
"""Copy of Q4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dApUStSzdNJwHFD4U5_Unyqj3ndofgh5

Q4. Investigate the possibility of predicting WHO-based Covid-19 Severity
using the species-level gut microbiome profile and specific metadata: Age,
BMI, Gender and the total number of comorbidities. Compare the relative
classification accuracy obtained using the three machine-learning based
classifiers: Random Forest, Support Vector Machines and k-Nearest
Neighbors. Identify the top 50 predictive features for this scheme.
First investigate the classification performance on the three different
groups. Then investigate the classification performance only between
mild and critical_severe groups.
Marks: 6
"""

from google.colab import drive
drive.mount('/content/drive')

#df = pd.read_excel('/content/drive/My Drive/path/to/excel_file.xlsx')

import pandas as pd
import numpy as np
from scipy.stats import kruskal, wilcoxon

# Load the metadata and clr transformed abundance profiles
metadata = pd.read_excel('/content/drive/MyDrive/HMDS1/Assignment1_Metadata.xlsx', index_col = 0)
clr_profiles = pd.read_excel('/content/drive/MyDrive/HMDS1/Assignment1_ClrTrans_Species.xlsx', index_col=0)
raw_counts = pd.read_excel('/content/drive/MyDrive/HMDS1/Assignment_RawCount_Species.xlsx', index_col=0)

metadata

import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report
import seaborn as sns
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.metrics import confusion_matrix, classification_report

new_metadata = metadata.loc[:, ['Age', 'BMI', 'Sex', 'comorbidities_total', 'WHO_severity']]
new_metadata

# Convert the severity values to numeric encodings
severity_mapping = {'mild': 1, 'moderate': 2, 'critical_severe': 3}
new_metadata['WHO_severity'] = new_metadata['WHO_severity'].map(severity_mapping)

# Convert the gender values to numeric encodings
gender_mapping = {'F': 1, 'M': 0}
new_metadata['Sex'] = new_metadata['Sex'].map(gender_mapping)

new_metadata

data = pd.concat([clr_profiles, new_metadata], axis=1)
#data = pd.concat([normalized_data, new_metadata], axis=1)
data= data.reset_index(drop=True)
data

nan_sum = data.isnull().sum()
print(nan_sum)

#data = data.dropna(subset=['Age'])

data

X = data.iloc[:, 0:-1] # features
y = data.iloc[:, -1] # labels
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train

#Without Top features selection and multiclassification
#Compare the relative classification accuracy obtained using the three machine-learning based classifiers: Random Forest, Support Vector Machines and k-Nearest Neighbors (without feature selection)
# Fit and evaluate Random Forest Classifier
rfc = RandomForestClassifier(n_estimators=100)
rfc.fit(X_train, y_train)
rfc_y_pred = rfc.predict(X_test)
rfc_accuracy = accuracy_score(y_test, rfc_y_pred)
rfc_cm = confusion_matrix(y_test, rfc_y_pred)
rfc_report = classification_report(y_test, rfc_y_pred)

# Fit and evaluate Support Vector Machine Classifier
svc = SVC(kernel='linear', C=1.0, random_state=42)
svc.fit(X_train, y_train)
svc_y_pred = svc.predict(X_test)
svc_accuracy = accuracy_score(y_test, svc_y_pred)
svc_cm = confusion_matrix(y_test, svc_y_pred)
svc_report = classification_report(y_test, svc_y_pred)

# Fit and evaluate k-Nearest Neighbors Classifier
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
knn_y_pred = knn.predict(X_test)
knn_accuracy = accuracy_score(y_test, knn_y_pred)
knn_cm = confusion_matrix(y_test, knn_y_pred)
knn_report = classification_report(y_test, knn_y_pred)


# Print the classification accuracies
print("Random Forest Classifier accuracy:", rfc_accuracy)
print("Support Vector Machine Classifier accuracy:", svc_accuracy)
print("k-Nearest Neighbors Classifier accuracy:", knn_accuracy)

# Print the confusion matrices
print("Random Forest Classifier confusion matrix:\n", rfc_cm)
print("Support Vector Machine Classifier confusion matrix:\n", svc_cm)
print("k-Nearest Neighbors Classifier confusion matrix:\n", knn_cm)

# Print the classification reports
print("Random Forest Classifier classification report:\n", rfc_report)
print("Support Vector Machine Classifier classification report:\n", svc_report)
print("k-Nearest Neighbors Classifier classification report:\n", knn_report)

# Create a DataFrame with the actual and predicted severity statuses for Random Forest Classifier
rfc_table = pd.DataFrame({'Actual Severity Status': y_test, 'Predicted Severity Status': rfc_y_pred})

# Create a DataFrame with the actual and predicted severity statuses for Support Vector Machine Classifier
svc_table = pd.DataFrame({'Actual Severity Status': y_test, 'Predicted Severity Status': svc_y_pred})

# Create a DataFrame with the actual and predicted severity statuses for k-Nearest Neighbors Classifier
knn_table = pd.DataFrame({'Actual Severity Status': y_test, 'Predicted Severity Status': knn_y_pred})

# Print the classification tables
print("Random Forest Classifier classification table:\n", rfc_table)
print("Support Vector Machine Classifier classification table:\n", svc_table)
print("k-Nearest Neighbors Classifier classification table:\n", knn_table)

# To Identify the top 50 predictive features we used SelectKBest, information gain, Mean Absolute Difference (MAD), Kendall Tau etc. As we can see the data is sparse so Kendall tau worked the best. 
# Select the top 50 features using SelectKBest and chi-squared test
from scipy.stats import kendalltau
from sklearn.feature_selection import SelectKBest, chi2
skb = SelectKBest(chi2, k=50)
X_new = skb.fit_transform(X, y) 

# Calculate the Kendall correlation between each feature and the target
correlations = []
for feature in X.columns:
    corr, pvalue = kendalltau(data[feature], data['WHO_severity'])
    correlations.append(corr)
    
# Sort the features by descending correlation coefficient
feature_ranking = sorted(zip(X.columns, correlations), key=lambda x: abs(x[1]), reverse=True)
top_features = [f[0] for f in feature_ranking[:50]]
print("Top 50 predictive features:", top_features)

y

#with top features and multiclassification
#investigate the classification performance on the three different groups.Compare the relative classification accuracy obtained using the three machine-learning based classifiers: Random Forest, Support Vector Machines and k-Nearest Neighbors (feature selection)
# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X[top_features], y, test_size=0.3, random_state=42)

y_test.shape

# Train and evaluate a random forest classifier
rfc = RandomForestClassifier(n_estimators=100, random_state=42)
rfc.fit(X_train, y_train)
rfc_pred = rfc.predict(X_test)
rfc_acc = accuracy_score(y_test, rfc_pred)
rfc_cm = confusion_matrix(y_test, rfc_pred)
rfc_report = classification_report(y_test, rfc_pred)


# Train and evaluate a KNN classifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
knn_pred = knn.predict(X_test)
knn_acc = accuracy_score(y_test, knn_pred)
knn_cm = confusion_matrix(y_test, knn_pred)
knn_report = classification_report(y_test, knn_pred)


# Train and evaluate an SVM classifier
svm = SVC(kernel='linear', random_state=42)
svm.fit(X_train, y_train)
svm_pred = svm.predict(X_test)
svm_acc = accuracy_score(y_test, svm_pred)
svc_cm = confusion_matrix(y_test, svm_pred)
svc_report = classification_report(y_test, svm_pred)


print("Random Forest Accuracy:", rfc_acc)
print("KNN Accuracy:", knn_acc)
print("SVM Accuracy:", svm_acc)

# Print the confusion matrices
print("Random Forest Classifier confusion matrix:\n", rfc_cm)
print("Support Vector Machine Classifier confusion matrix:\n", svc_cm)
print("k-Nearest Neighbors Classifier confusion matrix:\n", knn_cm)

# Print the classification reports
print("Random Forest Classifier classification report:\n", rfc_report)
print("Support Vector Machine Classifier classification report:\n", svc_report)
print("k-Nearest Neighbors Classifier classification report:\n", knn_report)

#significance : we got better accuracy after feature selection

#we found that after feature selction our prediction improved as shown above 
# Create a DataFrame with the actual and predicted severity statuses for Random Forest Classifier
rfc_table = pd.DataFrame({'Actual Severity Status': y_test, 'Predicted Severity Status': rfc_pred})

# Create a DataFrame with the actual and predicted severity statuses for Support Vector Machine Classifier
svc_table = pd.DataFrame({'Actual Severity Status': y_test, 'Predicted Severity Status': svm_pred})

# Create a DataFrame with the actual and predicted severity statuses for k-Nearest Neighbors Classifier
knn_table = pd.DataFrame({'Actual Severity Status': y_test, 'Predicted Severity Status': knn_pred})

# Print the classification tables
print("Random Forest Classifier classification table:\n", rfc_table)
print("Support Vector Machine Classifier classification table:\n", svc_table)
print("k-Nearest Neighbors Classifier classification table:\n", knn_table)

#investigate the classification performance only between mild and critical_severe groups i.e Binary Classification
top_features = ['Methanobrevibacter_smithii', 'Eubacterium_contortum', 'Clostridium_innocuum', 'Actinomyces_naeslundii', 'Clostridium_clostridioforme', 'Hespellia_porcina', 'Bacteroides_acidifaciens', 'Bacteroides_plebeius', 'Blautia_stercoris', 'Clostridium_irregulare', 'Anaerorhabdus_furcosa', 'Clostridium_sartagoforme', 'Clostridium_methylpentosum', 'Finegoldia_magna', 'Eggerthella_lenta', 'Dialister_invisus', 'Ruminococcus_lactaris', 'Clostridium_disporicum', 'Alistipes_finegoldii', 'Solobacterium_moorei', 'Clostridium_oroticum', 'Pseudoflavonifractor_capillosus', 'Melissococcus_plutonius', 'Robinsoniella_peoriensis', 'Enterococcus_casseliflavus', 'Bacteroides_nordii', 'Clostridium_lavalense', 'Actinomyces_graevenitzii', 'Clostridium_hathewayi', 'Lactonifactor_longoviformis', 'Eubacterium_oxidoreducens', 'Clostridium_saccharogumia', 'Clostridium_sporosphaeroides', 'Natranaerovirga_pectinivora', 'Lactobacillus_fermentum', 'Anaerosporobacter_mobilis', 'Acetivibrio_ethanolgignens', 'Escherichia.Shigella_flexneri', 'Megasphaera_micronuciformis', 'Eubacterium_cylindroides', 'Prevotella_stercorea', 'Clostridium_tertium', 'Clostridium_citroniae', 'Clostridium_leptum', 'Enterococcus_asini', 'Hydrogenoanaerobacterium_saccharovorans', 'Clostridium_asparagiforme', 'Peptococcus_niger', 'Marvinbryantia_formatexigens', 'Streptococcus_sanguinis']
data_new = data[top_features]
data_new = pd.concat([clr_profiles, new_metadata['WHO_severity']], axis=1)
data_new = data_new.reset_index(drop=True)

#drop the rows with moderate serverity 
data_new = data_new.drop(index=data_new[data_new['WHO_severity'] == 2].index)
X = data_new.iloc[:, 0:-1] # features
y = data_new.iloc[:, -1] # labels
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

#Compare the relative classification accuracy obtained using the three machine-learning based classifiers: Random Forest, Support Vector Machines and k-Nearest Neighbors (without feature selection)
# Fit and evaluate Random Forest Classifier
rfc = RandomForestClassifier(n_estimators=100)
rfc.fit(X_train, y_train)
rfc_y_pred = rfc.predict(X_test)
rfc_accuracy = accuracy_score(y_test, rfc_y_pred)
rfc_cm = confusion_matrix(y_test, rfc_y_pred)
rfc_report = classification_report(y_test, rfc_y_pred)


# Fit and evaluate Support Vector Machine Classifier
svc = SVC(kernel='linear', C=1.0, random_state=42)
svc.fit(X_train, y_train)
svc_y_pred = svc.predict(X_test)
svc_accuracy = accuracy_score(y_test, svc_y_pred)
svc_cm = confusion_matrix(y_test, svc_y_pred)
svc_report = classification_report(y_test, svc_y_pred)

# Fit and evaluate k-Nearest Neighbors Classifier
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
knn_y_pred = knn.predict(X_test)
knn_accuracy = accuracy_score(y_test, knn_y_pred)
knn_cm = confusion_matrix(y_test, knn_y_pred)
knn_report = classification_report(y_test, knn_y_pred)


# Print the classification accuracies
print("Random Forest Classifier accuracy:", rfc_accuracy)
print("Support Vector Machine Classifier accuracy:", svc_accuracy)
print("k-Nearest Neighbors Classifier accuracy:", knn_accuracy)

# Print the confusion matrices
print("Random Forest Classifier confusion matrix:\n", rfc_cm)
print("Support Vector Machine Classifier confusion matrix:\n", svc_cm)
print("k-Nearest Neighbors Classifier confusion matrix:\n", knn_cm)

# Print the classification reports
print("Random Forest Classifier classification report:\n", rfc_report)
print("Support Vector Machine Classifier classification report:\n", svc_report)
print("k-Nearest Neighbors Classifier classification report:\n", knn_report)

# Create a DataFrame with the actual and predicted severity statuses for Random Forest Classifier
rfc_table = pd.DataFrame({'Actual Severity Status': y_test, 'Predicted Severity Status': rfc_y_pred})

# Create a DataFrame with the actual and predicted severity statuses for Support Vector Machine Classifier
svc_table = pd.DataFrame({'Actual Severity Status': y_test, 'Predicted Severity Status': svc_y_pred})

# Create a DataFrame with the actual and predicted severity statuses for k-Nearest Neighbors Classifier
knn_table = pd.DataFrame({'Actual Severity Status': y_test, 'Predicted Severity Status': knn_y_pred})

# Print the classification tables
print("Random Forest Classifier classification table:\n", rfc_table)
print("Support Vector Machine Classifier classification table:\n", svc_table)
print("k-Nearest Neighbors Classifier classification table:\n", knn_table)

# we can see that Binary classification (mild annd critical) with selected features gave the better accuracy results than multiclass clasification.
#pipeline
#dataimport --- multiclass classification without feature selection --- multiclass classification with feature selction by kendall tau filter method -- binary class classification with selected feature -- comparision of accuracy (clasification report as well as table mentioned)
#note: Simple accuracy is the proportion of correctly classified instances to the total number of instances in the dataset. It is a basic metric to evaluate the performance of a classification model.
#Classification accuracy, on the other hand, takes into account the number of true positive, true negative, false positive, and false negative instances of each class. It is a more informative metric that provides a better understanding of how well a model performs for each class separately.
#Simple accuracy can be misleading when the dataset is imbalanced, which means that some classes have many more instances than others. In this case, the model can achieve a high accuracy by simply predicting the majority class for all instances. In contrast, classification accuracy provides a more accurate assessment of the model's performance for each class separately, regardless of the class distribution in the dataset.
#Therefore, simple accuracy and classification accuracy can differ, Thus Please see classification accuracy results while evaluating the assignment.